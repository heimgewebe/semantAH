name: Publish Daily Insights

on:
  schedule:
    # Run daily at 06:05 UTC (shortly after potential nightlies)
    - cron: '05 06 * * *'
  workflow_dispatch:
  push:
    paths:
      - 'scripts/export_daily_insights.py'
      - 'contracts/insights.daily.schema.json'
      - '.github/workflows/publish-insights-daily.yml'
    branches:
      - main

concurrency:
  group: publish-insights-daily
  cancel-in-progress: true

permissions:
  contents: write

jobs:
  publish-insights:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: astral-sh/setup-uv@v4
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: uv sync

      - name: Fetch Latest Observatory Snapshot
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          set -euo pipefail

          mkdir -p artifacts

          # Check for release existence with distinction between "Not Found" and "API Error"
          if RELEASE_CHECK=$(gh release view knowledge-observatory --repo "$GITHUB_REPOSITORY" 2>&1); then
            echo "Release found. STEADY STATE: snapshot is mandatory."

            DOWNLOAD_SUCCESS=0
            for delay in 5 10 15; do
              if gh release download knowledge-observatory --repo "$GITHUB_REPOSITORY" \
                --pattern "knowledge.observatory.json" \
                --dir "artifacts" \
                --clobber
              then
                DOWNLOAD_SUCCESS=1
                break
              fi
              echo "Attempt failed. Retrying in ${delay}s..."
              sleep $delay
            done

            if [[ "$DOWNLOAD_SUCCESS" -ne 1 ]] || [[ ! -s artifacts/knowledge.observatory.json ]]; then
              echo "::error::knowledge.observatory.json missing or empty although release exists."
              echo "::group::Diagnostics"
              gh --version
              gh api rate_limit || true
              echo "Available assets:"
              gh release view knowledge-observatory --repo "$GITHUB_REPOSITORY" --json assets -q '.assets[].name' || true
              echo "::endgroup::"
              exit 1
            fi

            # Integrity check
            echo "Verifying JSON integrity..."
            python3 -c "import json, sys; json.load(open(sys.argv[1], encoding='utf-8'))" artifacts/knowledge.observatory.json || { echo "::error::Snapshot artifact is corrupt (invalid JSON)."; exit 1; }
          else
             # Check if failure was "Not Found" or something else
            if echo "$RELEASE_CHECK" | grep -qiE "HTTP 404|Not Found|release.*not found"; then
              echo "::notice::No 'knowledge-observatory' release found. First-run without snapshot."
            else
              echo "::error::Release check failed with unexpected error (API/Auth/Rate-Limit)."
              echo "::group::Error Details"
              echo "$RELEASE_CHECK"
              gh --version
              gh api rate_limit || true
              echo "::endgroup::"
              exit 1
            fi
          fi

      - name: Generate Daily Insights
        run: |
          mkdir -p artifacts
          # Pass observatory path if it exists
          OBS_ARG=""
          if [[ -f "artifacts/knowledge.observatory.json" ]]; then
            OBS_ARG="--observatory artifacts/knowledge.observatory.json"
          fi

          uv run scripts/export_daily_insights.py \
            --output artifacts/insights.daily.json \
            $OBS_ARG

          # Strict artifact check
          test -s artifacts/insights.daily.json || { echo "::error::artifacts/insights.daily.json is missing or empty"; exit 1; }

      - name: Publish Release Asset
        env:
          GH_TOKEN: ${{ github.token }}
          RELEASE_TAG: insights-daily
        run: |
          # Create or update the release (ensure it is NOT a prerelease)
          gh release view "$RELEASE_TAG" || gh release create "$RELEASE_TAG" --title "Daily Insights" --notes "Automated publish of daily insights."
          gh release edit "$RELEASE_TAG" --prerelease=false

          # Upload the artifact (clobbering existing one)
          gh release upload "$RELEASE_TAG" artifacts/insights.daily.json --clobber

      - name: Notify Plexer
        id: notify
        if: success()
        continue-on-error: true
        env:
          PLEXER_URL: ${{ secrets.PLEXER_URL }}
          PLEXER_TOKEN: ${{ secrets.PLEXER_TOKEN }}
          RELEASE_TAG: insights-daily
        run: |
          set -euo pipefail

          # Skip if secrets are not available (e.g. in forks or initial setup)
          if [[ -z "${PLEXER_URL:-}" || -z "${PLEXER_TOKEN:-}" ]]; then
            echo "::notice::PLEXER_URL or PLEXER_TOKEN not set, skipping notification."
            exit 0
          fi

          # Extract timestamps from the artifact to ensure consistency
          GEN_AT=$(node -p "try { const d = JSON.parse(require('fs').readFileSync('artifacts/insights.daily.json','utf8')); d.metadata?.generated_at || '' } catch(e) { '' }" 2>/dev/null || true)
          TS=$(node -p "try { const d = JSON.parse(require('fs').readFileSync('artifacts/insights.daily.json','utf8')); d.ts || d.metadata?.ts || '' } catch(e) { '' }" 2>/dev/null || true)

          # Fallback to current time if artifact data is missing
          if [[ -z "$GEN_AT" ]]; then GEN_AT=$(date -u +"%Y-%m-%dT%H:%M:%SZ"); fi
          if [[ -z "$TS" ]]; then TS=$(date -u +"%Y-%m-%d"); fi

          URL="https://github.com/${{ github.repository }}/releases/download/${RELEASE_TAG}/insights.daily.json"

          # Calculate SHA256 (portable)
          if ! SHA=$( (sha256sum artifacts/insights.daily.json 2>/dev/null || shasum -a 256 artifacts/insights.daily.json) | cut -d ' ' -f 1 ); then
            echo "::error::SHA calculation failed for artifacts/insights.daily.json"
            exit 1
          fi

          # Ensure 64-character hex format
          if [[ ! "$SHA" =~ ^[a-f0-9]{64}$ ]]; then
            echo "::error::Invalid SHA format: $SHA"
            exit 1
          fi

          # Apply canonical prefix
          SHA="sha256:$SHA"

          # Extract canonical Schema Ref from contract
          SCHEMA_REF=$(jq -r '."$id"' contracts/insights.daily.schema.json 2>/dev/null || true)
          if [[ -z "${SCHEMA_REF}" || "${SCHEMA_REF}" == "null" ]]; then
            SCHEMA_REF="https://schemas.heimgewebe.org/contracts/insights.daily.schema.json"
          fi

          echo "::notice::Notifying Plexer: ts=$TS, generated_at=$GEN_AT, url=$URL, sha=$SHA, schema_ref=$SCHEMA_REF"

          # Construct notification payload
          cat > event.json <<EOF
          {
            "type": "insights.daily.published.v1",
            "source": "semantAH",
            "payload": {
              "ts": "$TS",
              "url": "$URL",
              "generated_at": "$GEN_AT",
              "sha": "$SHA",
              "schema_ref": "$SCHEMA_REF"
            }
          }
          EOF

          # Send to Plexer with X-Auth header (preferred) and capture response for debugging
          if ! curl -X POST "${PLEXER_URL%/}/events" \
            -H "Content-Type: application/json" \
            -H "X-Auth: ${PLEXER_TOKEN}" \
            -d @event.json \
            --fail-with-body \
            -o plexer_response.txt 2>plexer_error.log; then

            echo "::warning::Failed to notify plexer."
            echo "::group::Plexer Debug Logs"
            cat plexer_error.log || true
            cat plexer_response.txt || true
            echo "::endgroup::"

            # Redact secrets from logs
            sed -i "s/${PLEXER_TOKEN}/[REDACTED]/g" plexer_error.log plexer_response.txt 2>/dev/null || true

            # Save logs as artifact for post-mortem
            mkdir -p plexer_logs
            cp event.json plexer_logs/
            cp plexer_response.txt plexer_logs/
            cp plexer_error.log plexer_logs/
          fi

      - name: Upload Plexer Debug Logs
        if: always() && steps.notify.outcome == 'failure'
        uses: actions/upload-artifact@v4
        with:
          name: plexer-notification-logs-insights
          path: plexer_logs/
          if-no-files-found: ignore
          retention-days: 3
